{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. One-sided finite differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, `deriv`, which computes a derivative of its argument at a given point, $x$, using a one-sided finite difference rule with a given step side $h$, with the approximation order of $O(h^2)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv(f, x, h):\n",
    "    \"\"\" Compute a derivative of `f` at point `x` with step size `h`.\n",
    "    \n",
    "    Compute the derivative using the one-sided rule of the approximation order of $O(h^2)$.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        The function to differentiate\n",
    "    x : float\n",
    "        The point to compute the derivative at.\n",
    "    h : float\n",
    "        The step size for the finite different rule.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fder : derivative of f(x) at point x using the step size h.\n",
    "    \"\"\"\n",
    "    fder = (-3*f(x) + 4*f(x+h) - f(x+2*h))/(2*h)\n",
    "    return fder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test I.1\n",
    "\n",
    "Test your function on a simple test case: differentiate $f(x) = x^3$ at $x=0$. Comment on whether your results are consistent with the expected value of $f'(x) = 0$ and on an expected scaling with $h\\to 0$.\n",
    "\n",
    " (10% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010000 -- -0.0002\n",
      "0.001000 --  -2e-06\n",
      "0.000100 --  -2e-08\n",
      "0.000010 --  -2e-10\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    err = deriv(lambda x: x**3, x, h)\n",
    "    print(\"%5f -- %7.4g\" % (h, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка пропорциональна h^2, как и должно было быть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test I.2\n",
    "\n",
    "Now use a slightly more complicated function, $f(x) = x^2 \\log{x}$, evaluate the derivative at $x=1$ using your one-sided rule and a two-point one-sided rule. Roughly estimate the value of $h$ where the error stops decreasing, for these two schemes. \n",
    "(15% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def f(x):\n",
    "    return x**2 * log(x)\n",
    "    \n",
    "def fder(x):\n",
    "    return x * (2.*log(x) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv2(f, x, h):\n",
    "    fder = (f(x+h) - f(x-h))/(2*h)\n",
    "    return fder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 -- -6.617128391550597e-05 -- 3.333366667712667e-05\n",
      "0.001 -- -6.661673546126679e-07 -- 3.333333118415993e-07\n",
      "0.0001 -- -6.666276974875984e-09 -- 3.3332232529659223e-09\n",
      "1e-05 -- -4.901234973431201e-11 -- 3.433342499192804e-11\n",
      "1e-06 -- -1.9395574035740992e-10 -- -2.6422086740751638e-11\n",
      "1e-07 -- 1.694084206249613e-09 -- 2.8759217229890055e-11\n",
      "1e-08 -- -1.7179702216374437e-08 -- -5.263560698409719e-10\n",
      "1e-09 -- 1.9376267412773984e-07 -- 2.722921998987715e-08\n",
      "1e-10 -- 8.274037099909037e-08 -- 8.274037099909037e-08\n",
      "1e-11 -- 8.274037099909037e-08 -- 8.274037099909037e-08\n"
     ]
    }
   ],
   "source": [
    "for h in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11]:\n",
    "    err = deriv(f, 1, h) - fder(1)\n",
    "    err2 = deriv2(f, 1, h) - fder(1)\n",
    "    print(h,\"--\", err,\"--\", err2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По полученным данным можно заметить, что ошибка перестает уменьшаться при h равном примерно 10^(-8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test I.3 \n",
    "\n",
    "Now try differentiating $x^2 \\log(x)$ at $x=0$. Use the three-point one-sided rule. Note that to evaluate the function at zero, you need to special-case this value. Check the scaling of the error with $h$, explain your results. \n",
    "(25% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010000 -- -0.01386\n",
      "0.001000 -- -0.001386\n",
      "0.000100 -- -0.0001386\n",
      "0.000010 -- -1.386e-05\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x == 0:\n",
    "        # the limit of $x^2 log(x)$ at $x-> 0$ is zero, even though log(x) is undefined at x=0\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x**2 * log(x)\n",
    "    \n",
    "def fder(x):\n",
    "    if x == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x*(2*log(x) + 1)\n",
    "\n",
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    err = deriv(f, x, h) - fder(x)\n",
    "    print(\"%5f -- %7.4g\" % (h, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что ошибка пропорциональна h."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Midpoint rule "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which computes a definite integral using the midpoint rule up to a given error, $\\epsilon$. Estimate the error by comparing the estimates of the integral at $N$ and $2N$ elementary intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def midpoint_rule(func, a, b, eps):\n",
    "    \"\"\" Calculate the integral of f from a to b using the midpoint rule.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        The function to integrate.\n",
    "    a : float\n",
    "        The lower limit of integration.\n",
    "    b : float\n",
    "        The upper limit of integration.\n",
    "    eps : float\n",
    "        The target accuracy of the estimate.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    integral : float\n",
    "        The estimate of $\\int_a^b f(x) dx$.\n",
    "    \"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test II.1\n",
    "\n",
    "Test your midpoint rule on a simple integral, which you can calculate by paper and pencil.\n",
    "\n",
    "Compare the rate of convergence to the expected $O(N^{-2})$ scaling by studying the number of intervals required for a given accuracy $\\epsilon$.\n",
    "\n",
    "Compare the numerical results to the value you calculated by hand. Does the deviation agree with your estimate of the numerical error?\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... ENTER YOUR CODE AND COMMENTS HERE ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test II.2\n",
    "\n",
    "Now use your midpoint rule to compute the value of\n",
    "\n",
    "$$\n",
    "\\int_0^1\\! \\frac{\\sin{\\sqrt{x}}}{x}\\, dx\n",
    "$$\n",
    "\n",
    "up to a predefined accuracy of $\\epsilon=10^{-4}$.\n",
    "\n",
    "Note that the integral contains an integrable singularity at the lower limit. Do calculations two ways: first, do a straightforward computation; next, subtract the singularity. Compare the number of iterations required to achieve the accuracy of $\\epsilon$.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ... ENTER YOUR CODE HERE ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
